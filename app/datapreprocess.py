# -*- coding: utf-8 -*-
"""datapreprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11WwrIYlYxKhvY9xTp2LrvuaODlovQRKq

#**Day 3**

##Importing libraries and dataset
"""

#importing libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
import pickle

#importing dataset
df=pd.read_csv("/content/train - train (2).csv")
df

print(df.isnull().sum())

"""##Filling missing values
Backfilling missing values because the data is already in sorted order makes this method more preferable to our dataframe in terms of correctness.
"""

#filling the missing values by backfill method
df=df.fillna(method="bfill")
df

"""##Encoding
Here wind_direction column cannot be used in the mathematical equation of the model so we need to encode these variables into numbers. To achieve this get_dummies function is imported from the pandas library.
"""

#encoding
dummies = pd.get_dummies(df['wind_direction'])
df = df.drop('wind_direction',1)
df = pd.concat([df, dummies], axis=1)

"""##Data cleaning
Some unusual data entry format is found in columns such as **'month,'year',** and **'pressure'.** As a result, we check the location of such errors by applying the required condition and assigning a null to it.
"""

#replacing errors with null
for x in df.index:
  if df.loc[x,"month"]<1:
    df.loc[x,"month"]=None
  try:
    df.loc[x,"pressure"]=float(df.loc[x,"pressure"])
  except:
    df.loc[x,"pressure"]=None  
for x in df.index:
  try:
    df.loc[x,"year"]=int(df.loc[x,"year"])
  except:
     df.loc[x,"year"]=None

df.head()

"""##**Filling the replaced error using Backfilling**
Backfilling method is used to replace the missing data in this case. As the data set is already sorted concerning **hours, day, month, year**. So if we fill the missing values with mean-value, then the deviation would increase. Hence error would increase. The given features would be almost the same in the next hour also. For example, the temperature is 1.9 at a particular hour, then the next hour if the temperature would be around 1.9 only, not 14.356532039734322. So,backfilling method is chosen.
"""

# filling (backfill methid) the data after removal of unwanted datas
df=df.fillna(method="bfill")

df.head(30000)

df.isnull().sum().sum()

fig, ax = plt.subplots(figsize=(23,10))
sns.heatmap(df.corr(), cmap='coolwarm',center=0,  annot=True)

"""#Scaling
With the help of **minxmaxscaler()** from sklearn.preprocessing, the dataframe is scaled down to avoid variance and improve accuracy.
"""

#scaling
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
scaling = StandardScaler()#MinMaxScaler()
scaling.fit(df[['year','month','hour','pressure']])
df[['year','month','hour','pressure']]=scaling.fit_transform(df[['year','month','hour','pressure']])

df.head(20000)

#mean
df.mean().mean()

#median
df.median().median()

#removing duplicates
df.drop_duplicates(inplace=True)

df

"""#**Day 4-5**

##Dropping wind_direction
Dropping the column with dummy wind direction values and assigning it to a new dataframe called 'df1'. Because we've previously encoded the dataframe, it has no effect on any of the columns.
"""

df1 = df.drop(['E','ENE','ESE','N','NE','NNE','NNW','NW','S','SE','SSE','SSW','SW','W','WNW','WSW'],1)
df1

#REPLACING OUTLIER IN wind_speed COLUMN BY MEDIAN METHOD

# Position of the Outlier
print(np.where(df['wind_speed']>-60))
#replacing lower outlier
median = df.loc[df['wind_speed']>-60, 'wind_speed'].median()
df.loc[df.wind_speed<-60, 'wind_speed'] = np.nan
df.fillna(median,inplace=True)
#replacing upper outlier
print(np.where(df['wind_speed']>4))
median1 = df.loc[df['wind_speed']>4, 'wind_speed'].median()
df.loc[df.wind_speed>4, 'wind_speed'] = np.nan
df.fillna(median1,inplace=True)
df.boxplot(['wind_speed'])

#REPLACING OUTLIER IN rain COLUMN BY MEDIAN METHOD
# Position of the Outlier
print(np.where(df['rain']>0))
median2 = df.loc[df['rain']>0, 'rain'].median()
df.loc[df1.rain>0, 'rain'] = np.nan
df.fillna(median2,inplace=True)
df.boxplot(['rain'])


df=df.drop(['day'],1)


df= df.loc[:, ~df.columns.str.contains('^Unnamed')]
df

"""##Splitting the Dataset
Dataset is splitted into 70:30 ratio for training and testing. Here, we’ll create the x and y variables by taking them from the dataset and using the train_test_split function of scikit-learn to split the data into training and test sets.
"""

x = df.drop(['PM2.5'],axis=1)
y = df[['PM2.5']]

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
print(x.shape)

"""##Random Forest
We’re going to use x_train and y_train, obtained above, to train our random forest regression model. We’re using the fit method and passing the parameters as shown below.

"""

#1st algorithm
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import accuracy_score
reg = RandomForestRegressor(n_estimators=13, random_state=0)
#training the dataset
reg.fit(x_train,y_train.values.ravel())

"""##Model Evaluation
we need to check to see how well our model is performing on the test data. For this, we evaluate our model by finding the R^2.
"""

#printing accuracy by r^2
reg.score(x_test, y_test)

reg.score(x_train, y_train)

"""##Prediction
Once the model is trained, it’s ready to make predictions. We can use the predict method on the model and pass x_test as a parameter to get the output as y_pred.
"""

print("Predicted values of PM 2.5:", reg.predict(x_test))
y_pred = reg.predict(x_test)
y_pred.shape



pickle.dump(reg, open('model.pkl','wb'))

model = pickle.load(open('model.pkl','rb'))
